== Writing ZaggClient Checks

This document is intended to be used as a reference to write checks in Openshift V3 using the Zagg interface.

*Note:* This document assumes you are using the https://github.com/openshift/openshift-tools/tree/master/docker/oso-rhel7-host-monitoring[oso-rhel7-host-monitoring] docker container.  This container includes all the required libraries to communicate with a Zagg server.

==== A Note About ZaggClient Checks

Let's take a quick review and understanding of Zagg and Zabbix to clarify what is meant by 'ZaggClient checks'.

ZaggClient checks are simple gathering of Zabbix items and sending them to the ZaggServer (which eventually sends them to a Zabbix Server).

*Note: This document assumes that that the item has already been configured in Zabbix.  These checks will update the items, but will not add them.  Please configure Zabbix appropriately.*

==== Dynamic Zagg/Zabbix Objects

Zagg supports Zabbix dynamic object support.  Explaining the Low Level Discovery rules is out of scope of this document.  Please refer to https://www.zabbix.com/documentation/2.4/manual/discovery/low_level_discovery[Zabbix's documentation] for more information.

This document will show how to add dynamic objects and items, then show how to send data to update those items.

Dynamic objects in Zabbix require 3 things:

* discovery key (defined in Zabbix Template -> Discovery Rule)
* Macro Identifier - string to identify the Macro (we call this the macro string)
* Macro Name(s) - string(s) to name an invidual object.

Dynamic objects need to continually be updated in Zabbix.  If they are not, Zabbix will expunge the objects after a defined set of time.

After these are created, we can start creating dynamic items (defined in Zabbix) to monitor.

A real world example.  Let's say that we want to monitor all file systems on the system and how much space they are using.  All systems are not going to have the same file systems, so this is a perfect use case for dynamic objects.

In this example, the discovery key would be "filesystems"
The Macro Identifier would be "#FILESYSTEMS".  The capatilization and the '#' are Zabbix conventions
The Macro Names would be the file systems we want to monitor "/", "/var", "/home"

More examples will be shown below on how to write and collect dynamic data.

=== Zagg Clients Overview

Currently there are two different methods that can be used to send data to Zagg.

. *ZaggSender python libraries*:  This is the *PREFERRED* way to write checks. ZaggSender is a python interface used to send data to Zagg

. *ops-zagg-client*:  This is a command line tool that can be used to send data to Zagg.

Both of these clients read their default settings from the config file: `/etc/openshift_tools/zagg_client.yaml`.


==== ZaggSender - Python API

This is a python API used to create and send data to Zagg.

ZaggSender is maintained in the https://github.com/openshift/openshift-tools/tree/master/openshift_tools/monitoring[openshift-tools] repository.  It is installed via the `python-openshift-tools-monitoring-zagg` RPM.

ZaggSender reads it's default settings from the config file: `/etc/openshift_tools/zagg_client.yaml`.

The basic (but still passing Pylint) python script would follow the pattern:

.ZaggSender python script basic pattern
----
#!/usr/bin/env python
'''
   Command to send some data to Zabbix
'''

#This is not a module, but pylint thinks it is.  This is a command.
#pylint: disable=invalid-name

import subprocess
from openshift_tools.monitoring.zagg_sender import ZaggSender

def main():
    ''' Get data, send to zabbix
    '''
    # this this the command I want to run
    my_command = "foo"
    output = subprocess.check_output(my_command, shell=True)

    # we now have all the data we want.  Let's send it to Zagg
    zs = ZaggSender()
    zs.add_zabbix_keys({
                     'item1' : 'value1',
                     'item2' : 'value2',
                  })
    zs.send_metrics()

if __name__ == '__main__':
    main()


----

===== Zabbix Item/Value pair Example

Here is an example script of capturing the response code of google.com and sending it to Zagg as Zabbix item "web.google.status":

.ZaggSender Python Example Script
----
#!/usr/bin/env python

import urllib
import yaml
from openshift_tools.monitoring.zagg_sender import ZaggSender

resp = urllib.urlopen('http://www.google.com')
google_response = resp.getcode()

zs = ZaggSender()
zs.add_zabbix_keys({ 'web.google.status' : google_response })
zs.send_metrics()

----

===== Python Dynamic Object/item example

Here is an example on how to write a dynamic object that uses the macros strings and macro names.

In this example we will assume that we want to monitor a file system that has this output of 'df -h'
----
$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda2       219G   62G  158G  29% /
devtmpfs        9.7G     0  9.7G   0% /dev
tmpfs           9.8G  8.0K  9.8G   1% /dev/shm
tmpfs           9.8G  281M  9.5G   3% /run
tmpfs           9.8G     0  9.8G   0% /sys/fs/cgroup
/dev/sda1       497M  291M  207M  59% /boot
/dev/md0         11T  60.1G 40.8G 56% /home
----
In this example we want to report on /, /boot, and /home.  The tmpfs drives can be ignored at this time.

* First, in Zabbix we would add a discovery rule under a template.  We would call the key in that discover rule "filesystems"
* Next, we would add a dynamic item under this newly created discovery rule called "filesystem.percent_full"
* We will use the Macro string of "#FILESYSTEM"


.ZaggSender python dynamic item script example
----
#!/usr/bin/evn python
import subprocess
from openshift_tools.monitoring.zagg_sender import ZaggSender

df_cmd = "df"

# get the output of df
output = subprocess.check_output(df_cmd, shell=True)

# this will only collect the filesystems we care about, and strip out the other lines
filesystem_list = [f for f in output.split('\n') if f.startswith("/dev")]

# we need a dict in the format of {"filesystem1_name" : "% free"}
filesystem_dict = {}
for f in filesystem_list:
    line = f.split()
    filesystem_dict[line[5]] = line[4].replace("%","")

# we now have all the data we want.  Let's send it to Zagg

zs = ZaggSender()

# This will bundle up the dynamic object
zs.add_zabbix_dynamic_item('filesystem', '#FILESYSTEM', filesystem_dict.keys() )

# This will bundle up the dynamic items
for filesys_name, filesys_percent in filesytem_dict.iteritems():
    zs.add_zabbix_keys({'%s[%s]' % ('#FILESYSTEM', filesys_name): filesys_percent})

# Finally, sent them to zabbix
zs.send_metrics()
----

==== ops-zagg-client

This is a command line tool written in python that can send Zabbix items directly to the zagg server.  This tool is similar to the Zabbix command line tool `zabbix_sender`.  This tool packages up Zabbix items and "ships" them to a Zagg Server.

By default, `ops-zagg-client` reads defaults out of the config file: `/etc/openshift_tools/zagg_client.yaml`. These values can be overridden from the command line.

The command line options were modeled after the `zabbix_sender` command.  By using these relevant options, checks can be created and data can be sent to Zagg:

.ops-zagg-client CLI Options
----
  -h, --help            show this help message and exit

Defaults of these values read from /etc/openshift_tools/zagg_client.yaml:

  -s HOST, --host HOST  specify host name to identify as (the name registered in Zabbix)
  -z ZAGG_SERVER, --zagg-server ZAGG_SERVER  hostname of IP of Zagg server
  --zagg-user ZAGG_USER  username of the Zagg server
  --zagg-pass ZAGG_PASS  password of the Zagg server
  -c CONFIG_FILE, --config-file CONFIG_FILE (alternative config file)

These values are needed for the unique Zabbix items:

  -k KEY, --key KEY     zabbix key
  -o VALUE, --value VALUE  zabbix value

----

===== ops-zagg-client item example

`ops-zagg-client` can be used to write bash scripts.  The basic bash script would follow the pattern:

.ops-zagg-client bash script pattern
----
#!/bin/bash

<do checks and gather data>

ops-zagg-client -k sample_key1 -o sample_value1
ops-zagg-client -k sample_key2 -o sample_value2
----

Here is an example script of capturing the response code of google.com and sending it to Zagg as Zabbix item "web.google.status":

.ops-zagg-client example script
----
#!/bin/bash

GOOGLE_STATUS=$(curl -I http://www.google.com 2>/dev/null | head -n 1 | awk '{print $2}')

ops-zagg-client -k web.google.status -o ${GOOGLE_STATUS}
----

===== ops-zagg-client Dynamic Object and item example

Here is an example on how to write a dynamic object that uses the macros strings and macro names.

In this example we will assume that we want to monitor a file system that has this output of 'df -h'
----
$ df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda2       219G   62G  158G  29% /
devtmpfs        9.7G     0  9.7G   0% /dev
tmpfs           9.8G  8.0K  9.8G   1% /dev/shm
tmpfs           9.8G  281M  9.5G   3% /run
tmpfs           9.8G     0  9.8G   0% /sys/fs/cgroup
/dev/sda1       497M  291M  207M  59% /boot
/dev/md0         11T  60.1G 40.8G 56% /home
----
In this example we want to report on /, /boot, and /home.  The tmpfs drives can be ignored at this time.

* First, in Zabbix we would add a discovery rule under a template.  We would call the key in that discover rule "filesystems"
* Next, we would add a dynamic item under this newly created discovery rule called "filesystem.percent_full"
* We will use the Macro string of "#FILESYSTEM"

The options in _ops-zagg-client_ that will allow us to send dynamic items are as follows:
----
$ ops-zagg-client --help
...
Sending a Low Level Discovery Item:
  --discovery-key DISCOVERY_KEY
                        discovery key
  --macro-string MACRO_STRING
                        macro string
  --macro-names MACRO_NAMES
                        comma seperated list of macro names
----

.ops-zagg-client dynamic script example
----
#!/bin/bash

# we need a list of file systems in for format of "/filesystem1,/filesystem2,/filesystem3"
FILESYSTEMS=$(df | grep '^/dev'| awk '{print $NF}' | xargs echo | tr " " ",")

# Create and send the dynamic items with ops-zagg-client
ops-zagg-client --discovery-key filesystems --macro-string '#FILESYSTEM' --macro-names $FILESYSTEMS

# Now send each filesystem percentage stat with ops-zagg-client
#  example:
#  ops-zagg-client -k 'filesystem.percent_full[/]' -o 15
#  ops-zagg-client -k 'filesystem.percent_full[/home]' -o 50
#  ops-zagg-client -k 'filesystem.percent_full[/var]' -o 64
FS=$(df | grep '^/dev'| awk '{print $(NF-1), $NF}'  | tr -d '%' | tr " " ",")
for f in $FS; do
    FILESYS=$(echo f | awk '{print $2}')
    FILESYS_PERCENT=$(echo f | awk '{print $1}')
    ops-zagg-client -k "filesys.percent_full[$FILESYS]" -o $FILESYS_PERCENT
----


==== Dynamic Items in Zabbix with python

The official documentation was not trivial to understand, so this example seemed much clearer to show how they work and what we need to do in code to make it happen.

Going to use the the cron-send-filesystem-metrics script as an example. On this test environment it finds 2 discs that wants to report, we shall store it in the filesys list
----
filesys: ['/dev/mapper/baal-root', '/dev/mapper/baal-var']
----

Zabbix setup coming from ansible/roles/os_zabbix/vars/template_os_linux.yml creates the required discovery rule named "disc.filesys" and the two (_disc.filesys.full_ and _disc.filesys.inodes.pused_) item prototypes that use a macro used by the script and zabbix for substitution (#OSO_FILESYS). 
In the script these values are used as
----
   discovery_key_fs = 'disc.filesys'
   item_prototype_macro_fs = '#OSO_FILESYS'
   item_prototype_key_full = 'disc.filesys.full'
   item_prototype_key_inode = 'disc.filesys.inodes.pused'
----
First, ZaggSender needs to know what dynamic values will be replacing the #OSO_FILESYS  macro in the item prototypes. This is done with the ZaggSender method named add_zabbix_dynamic_items, that looks like the following
----
filesys = ['/dev/mapper/baal-root', '/dev/mapper/baal-var']
zagg_sender.add_zabbix_dynamic_item(discovery_key_fs, item_prototype_macro_fs, filesys)
----
The result of this line of code can be seen later on in the ZaggSender unique metrics printout that is included fully at the end, but this code is responsible for adding a data key with the value being the list of filesystems that it should expect once the actual data corresponding to those dynamic values will be sent:
----
UniqueMetric('UNNAMED-ZAGG-CLIENT-CTR', 'disc.filesys', '{"data": [{"{#OSO_FILESYS}": "/dev/mapper/baal-root"}, {"{#OSO_FILESYS}": "/dev/mapper/baal-var"}]}', 1468530031, 'a835b16566d6462d81fdfb3b15fc46f9')
----

Then for each item prototype our script has to match the item's key with what we want to send, in this case disc.filesys.full[{#OSO_FILESYS}] and disc.filesys.inodes.pused[{#OSO_FILESYS}]
----
zagg_sender.add_zabbix_keys({'%s[%s]' % (item_prototype_key_full, "/dev/mapper/baal-root"): 14.753461518016865})
zagg_sender.add_zabbix_keys({'%s[%s]' % (item_prototype_key_full, "/dev/mapper/baal-var"): 3.5051553182188537})
----
Zabbix thus gets a key named _disc.filesys.full[/dev/mapper/baal-root]_ with the value 14.753461518016865, and that key will match the prototype's key (_disc.filesys.full[{#OSO_FILESYS}]_). Since zabbix knows from the dynamic item setup that #OSO_FILESYS can have the value /dev/mapper/baal-root it will recognize it and therefore it will be filed under the discovery rule and stored.

The other item prototype in this script is filled in the same manner.

The whole output from a ZaggSender.print_unique_metrics() that shows what is sent over when a dynamic item is prepared for zabbix. It shows that basically we want to send a list of values that will be replaced by the macros in prototype items and then actually send those items with values.
----
ZaggSender UniqueMetrics:
==============================
UniqueMetric('UNNAMED-ZAGG-CLIENT-CTR', 'disc.filesys', '{"data": [{"{#OSO_FILESYS}": "/dev/mapper/baal-root"}, {"{#OSO_FILESYS}": "/dev/mapper/baal-var"}]}', 1468530031, 'a835b16566d6462d81fdfb3b15fc46f9')
UniqueMetric('UNNAMED-ZAGG-CLIENT-CTR', 'disc.filesys.full[/dev/mapper/baal-root]', 14.753461518016865, 1468530031, '513ec4e3a9444b1b9fc34c4cc3f7860d')
UniqueMetric('UNNAMED-ZAGG-CLIENT-CTR', 'disc.filesys.full[/dev/mapper/baal-var]', 3.5051553182188537, 1468530031, 'f65dc71418624b089febe9b8e9791e6a')
UniqueMetric('UNNAMED-ZAGG-CLIENT-CTR', 'disc.filesys.inodes.pused[/dev/mapper/baal-root]', 9.850189208984375, 1468530031, '2be294d5e724445690398c0b451663ff')
UniqueMetric('UNNAMED-ZAGG-CLIENT-CTR', 'disc.filesys.inodes.pused[/dev/mapper/baal-var]', 0.27045283176943696, 1468530031, '6f8a7f92ad844a94b66762af2ecdba51')
==============================
----

If we would want to add an additional metric to this script, let's say random access times on each volume. First we would have to create a new item prototype in the template_os_linux.yml file, that could be named _disc.filesys.rat[{#OSO_FILESYS}]_
----
  - discoveryrule_key: disc.filesys
    name: "disc.filesys.rat.{#OSO_FILESYS}"
    key: "disc.filesys.rat[{#OSO_FILESYS}]"
    value_type: float
    description: "some magical utility that gives us filesys.rat numbers"
    applications:
    - Disk

----
Once we have the random access time numbers, then in the cron send script we would add
----
item_prototype_key_rat = 'disc.filesys.rat'
rat_values = ['110', '117'] #example values
zagg_sender.add_zabbix_keys{'%s[%s]' % (item_prototype_key_rat, "/dev/mapper/baal-root"): rat_value[0]})
zagg_sender.add_zabbix_keys{'%s[%s]' % (item_prototype_key_rat, "/dev/mapper/baal-var"): rat_value[1]})
----
