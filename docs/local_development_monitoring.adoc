// vim: ft=asciidoc

= How to do local development of openshift-tools monitoring components
:toc: macro
:toc-title:

toc::[]


== Description
The purpose of this document is to show how development of openshift-tools monitoring components can be developed locally.

The monitoring components of openshift-tools run inside of containers, so we use containers to develop them as well. The Zabbix and Zagg related pieces run as containers inside of a local OpenShift environment, and the host monitoring container runs as a container outside of the local OpenShift environment.

In this document, we're going to focus on the monitoring components, but similar patterns can be used for other components as well.


== Prerequisites

=== Packages
.The following packages are required:
. Docker
. ansible

.Fedora:
----
sudo dnf -y install docker ansible
----


=== Services
.The following services need to be enabled and started:
. docker

.Fedora:
----
sudo systemctl enable docker
sudo systemctl start docker
sudo systemctl status docker
----

=== OpenShift oc binary
The `oc` client tool to setup a local OpenShift environment is required.  The oc binary can be downloaded from https://github.com/openshift/origin/releases (put the oc binary somewhere in your $PATH).

You can install multiple versions of `oc` and use a symlink to decide which version to run with.
----
$ ll ~/bin/oc*
lrwxrwxrwx. 1 user1 user1        10 Dec 16 13:42 /home/user1/bin/oc -> ./oc-1.3.2
-rwxr-xr-x. 1 user1 user1  96989318 Dec 13 16:50 /home/user1/bin/oc-1.3.2
-rwxr-xr-x. 1 user1 user1 107440536 Feb 13 15:36 /home/user1/bin/oc-1.4.1
----

== Containers
=== Locating the containers
The local development environment uses CentOS versions of the containers found in https://github.com/openshift/openshift-tools/tree/prod/docker. These containers are periodically built and pushed to the public Docker hub at https://hub.docker.com/u/openshifttools/ (the local development setup scripts will automatically download them).

If you are interested in modifying the containers yourself, you can build them from the Dockerfiles in https://github.com/openshift/openshift-tools/tree/prod/docker (just be sure to tag your locally built containers with the same names that the `start-local-dev-env.sh` and the `zabbix_monitoring_cent7_local_dev.yaml` template tries to pull/reference. See https://github.com/openshift/openshift-tools/tree/prod/docker/README.adoc for more details.

=== Running the monitoring containers locally
Go into openshift-tools/docker/local_development and run the `start-local-dev-env.sh` script.

----
cd openshift-tools/docker/local_development
./start-local-dev-env.sh
----

If this is the first time you're running the script, it may fail with a message like this:

----
-- Checking Docker daemon configuration ... FAIL
   Error: did not detect an --insecure-registry argument on the Docker daemon
   Solution:

     Ensure that the Docker daemon is running with the following argument:
     	--insecure-registry 172.30.0.0/16
----

Go ahead and add that parameter to docker by editing `/etc/sysconfig/docker` and setting the INSECURE_REGISTRY variable. Something like this:

----
# If you have a registry secured with https but do not have proper certs
# distributed, you can tell docker to not look for full authorization by
# adding the registry to the INSECURE_REGISTRY line and uncommenting it.
# INSECURE_REGISTRY='--insecure-registry'
INSECURE_REGISTRY='--insecure-registry 172.30.0.0/16'
----

Then restart docker.

----
[user@box ~]$ sudo systemctl restart docker
[sudo] password for user: 
[user@box ~]$ 
----



start-local-dev-env.sh will do the following:

* Open a firewall port on port 53 so that OpenShift containers can do DNS resolution to other OpenShift containers. The change is ephemeral, so restarting firewalld should undo the change.
* Run `oc cluster up` to bring up a local OpenShift cluster.
* Create SSL certificates (if none are found in the local directory).
* Install/apply the OpenShift template with the Zabbix and Zagg containers.
* Make entries in your machine's /etc/host so that you can access the OpenShift containers through known DNS/host names (ie oso-cent7-zabbix-web and oso-cent7-zagg-web).
* Configure Zabbix with `openshift-tools/ansible/playbooks/adhoc/zabbix_setup/oo-config.zaio.yml`.
* Start up a docker container running the oso-centos7-host-monitoring container that will monitor and report to Zabbix on the health of your local host.

=== Logging into Zabbix
Once the `start-local-dev-env.sh` script is complete, you can log into Zabbix at https://oso-cent7-zabbix-web.

The username is `Admin`.
The password is `zabbix`.

=== Logging into OpenShift
You can log into the OpenShift web UI at https://localhost:8443/console

The username is `developer`.
The password is `developer`.

You can also use the `oc` CLI tool by logging in with `oc login -u developer -p developer`

You can run `oc` commands as the OpenShift admin by prefixing your `oc` commands with `sudo`.

=== Running commands inside the containers
For the OpenShift containers, you can get a shel environment with `oc rsh <container-name>`.

For the host-monitoring container you can get a shell with `sudo docker exec -ti oso-centos7-host-monitoring bash`.


== Cleaning up
To clean up, you can run `openshift-tools/docker/local_development/stop-local-dev-env.sh

This will:

* Stop the local OpenShift environemnt with `oc cluster down`
* Stop the oso-centos7-host-monitoring container with `docker stop` and `docker rm`

The generated SSL certificates will stay on the local filesystem, so future invocations of `start-local-dev-env.sh` will re-use them.
